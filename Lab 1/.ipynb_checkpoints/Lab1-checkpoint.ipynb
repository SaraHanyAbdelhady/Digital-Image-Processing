{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">LAB 1</h1>\n",
    "<h1 style=\"text-align:center;\">Spatial Domain Filtering</h1>\n",
    "<h3 style=\"text-align:left; color:blue;\">Student Name:</h3>\n",
    "<h3 style=\"text-align:left; color:blue;\">Student ID:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:left; color:black;\">Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial domain filtering is a fundamental technique used in image processing to modify or enhance images based on their pixel values in the spatial domain. Here pixels of the image are directly manipulated without transforming the image.\n",
    "\n",
    "Spatial domain filters operate by convolving the image with a filter kernel or mask, which is a small matrix that defines the weights or coefficients for combining the pixel values. The filter kernel is typically a small square or rectangular matrix, with each element specifying the contribution of its corresponding pixel to the filtered result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:left; color:black;\">Objective</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll be introduced to some python libraries commonly used for image processing which are:</br>\n",
    "* OpenCV.</br>\n",
    "* Numpy.</br>\n",
    "* Matplotlib.</br>\n",
    "\n",
    "You'll use these libraries to do some basic operations:</br>\n",
    "* Reading a colored image from disk.</br>\n",
    "* Checking the image properties (shape, datatype, and size).</br>\n",
    "* Slicing an image.</br>\n",
    "* Flipping an image.</br>\n",
    "* Converting an image to grayscale.</br>\n",
    "* Inspecting the separate BGR channels of an image.</br>\n",
    "\n",
    "Then, you'll apply some spatial domain filtering techniques on some images to:</br>\n",
    "* Smooth an image using averaging, gaussian and median filters.</br>\n",
    "* Sharpen an image using Sobel and Laplacian filter.</br>\n",
    "* Threshold an image and check its histogram.</br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:left; color:black;\">Instructions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an image from disk\n",
    "# flags: loads the image in the BGR 8-bit format\n",
    "input_image = cv2.imread(filename=\"lenna.png\", flags=cv2.IMREAD_COLOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show an image using matplotlib\n",
    "def show(image, colored = True):\n",
    "    if colored:\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(rgb_image)\n",
    "    else:\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "show(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the array dimensions of the input image\n",
    "print(\"BGR Image shape = \", input_image.shape)\n",
    "# Print the data type of the input image\n",
    "print(\"BGR Pixel type is \", input_image.dtype)\n",
    "# Print the input image size in bytes\n",
    "print(\"BGR Image size = \", input_image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get part of the image (array slicing [start: end+1])\n",
    "sliced_image = input_image[200:400, 200:400]\n",
    "show(sliced_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip image: 0 for vertical flip, 1 for horizontal flip, -1 for both\n",
    "flipped_vertically = cv2.flip(src=input_image, flipCode=0)\n",
    "show(flipped_vertically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the BGR image to GRAYSCALE image and check its size\n",
    "gray_image = cv2.cvtColor(src=input_image, code=cv2.COLOR_BGR2GRAY)\n",
    "print(\"Gray image shape = \", gray_image.shape)\n",
    "show(gray_image, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split B, G, R channels of input image\n",
    "b, g, r = cv2.split(m=input_image)\n",
    "# Display red channel only\n",
    "zero = np.zeros(shape=b.shape, dtype=np.uint8)\n",
    "red_channel = cv2.merge(mv=[zero, zero, r])\n",
    "show(red_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customized averaging filter and apply it to the image\n",
    "filter_length = 15\n",
    "average_filter = np.ones(shape=(filter_length, filter_length), dtype=np.uint8) / ((filter_length) ** 2)\n",
    "averaged_image = cv2.filter2D(src=gray_image, ddepth=-1, kernel=average_filter)\n",
    "show(averaged_image, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply OpenCV averaging filters\n",
    "blurred_image = cv2.blur(src=input_image, ksize=(11, 11)) # of the same datatype\n",
    "box_filtered_image = cv2.boxFilter(src=input_image, ddepth=-1, ksize=(9,9))\n",
    "plt.subplots(1, 2, figsize=(15, 15))\n",
    "plt.subplot(1,2,1)\n",
    "show(blurred_image)\n",
    "plt.subplot(1,2,2)\n",
    "show(box_filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply OpenCV Gaussian filter\n",
    "gaussian_image = cv2.GaussianBlur(src=input_image, ksize=(9,9), sigmaX=0)  # sigmaY=sigmaX\n",
    "plt.subplots(1, 1, figsize=(7, 7))\n",
    "show(gaussian_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an image corrupted with salt and pepper noise and apply median filter\n",
    "salt_and_pepper_image = cv2.imread(filename=\"salt_and_pepper.png\", flags=cv2.IMREAD_GRAYSCALE)\n",
    "median_image = cv2.medianBlur(src=salt_and_pepper_image, ksize=3)\n",
    "averaged_image_salt_pepper = cv2.blur(src=salt_and_pepper_image, ksize=(3,3))\n",
    "plt.subplots(1, 3, figsize=(15, 15))\n",
    "plt.subplot(1,3,1)\n",
    "show(salt_and_pepper_image, False)\n",
    "plt.subplot(1,3,2)\n",
    "show(median_image, False)\n",
    "plt.subplot(1,3,3)\n",
    "show(averaged_image_salt_pepper, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Sobel filter to detect edges in an image\n",
    "sobel_x = cv2.Sobel(src=gray_image, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=3)\n",
    "sobel_y = cv2.Sobel(src=gray_image, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=3)\n",
    "sobel_approximate_mag = (np.absolute(sobel_x)+ np.absolute(sobel_y))\n",
    "# Normalize the result to range 0 to 255\n",
    " # First parameters: input image\n",
    " # Second parameter: output image\n",
    "sobel_x = cv2.normalize(np.absolute(sobel_x), None, 0, 255,cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "sobel_y = cv2.normalize(np.absolute(sobel_y), None, 0, 255,cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "sobel_approximate_mag = cv2.normalize(sobel_approximate_mag, None, 0, 255,cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "plt.subplots(1, 3, figsize=(15, 15))\n",
    "plt.subplot(1,3,1)\n",
    "show(sobel_x, False)\n",
    "plt.subplot(1,3,2)\n",
    "show(sobel_y, False)\n",
    "plt.subplot(1,3,3)\n",
    "show(sobel_approximate_mag, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Laplacian filter to detect edges in an image\n",
    "laplacian_image = cv2.Laplacian(src=gray_image, ddepth=cv2.CV_64F) # default ksize=1 apply the 3x3 laplacian filter\n",
    "laplacian_image_abs = np.absolute(laplacian_image)\n",
    "laplacian_image_abs = cv2.normalize(laplacian_image_abs, None, 0, 255,cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "plt.subplots(1, 1, figsize=(7, 7))\n",
    "show(laplacian_image_abs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpening an image\n",
    "sharpened_image = np.absolute(gray_image - laplacian_image)\n",
    "sharpened_image = cv2.normalize(sharpened_image, None, 0, 255,cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "plt.subplots(1, 1, figsize=(7, 7))\n",
    "show(sharpened_image, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold an image\n",
    "threshold, thresh_image = cv2.threshold(src=gray_image, thresh=127, maxval=255, type=cv2.THRESH_BINARY)\n",
    "show(thresh_image, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the histogram of an image\n",
    "# mask is used to compute histogram for certain part of the image where the mask not equal zero, it is an array of same size as image\n",
    "gray_image_histogram = cv2.calcHist(images=[gray_image], channels=[0], mask=None, histSize=[256], ranges=[0,256])\n",
    "plt.plot(gray_image_histogram)\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Pixel number\")\n",
    "plt.title(\"Histogram of Gray Image\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
